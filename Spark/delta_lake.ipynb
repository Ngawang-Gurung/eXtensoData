{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install delta-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a spark session with Delta\n",
    "builder = SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark context\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Delta table creation\n"
     ]
    }
   ],
   "source": [
    "# Create a spark dataframe and write as a delta table\n",
    "\n",
    "print(\"Starting Delta table creation\")\n",
    "\n",
    "data = [(\"Robert\", \"Baratheon\", \"Baratheon\", \"Storms End\", 48),\n",
    "        (\"Eddard\", \"Stark\", \"Stark\", \"Winterfell\", 46),\n",
    "        (\"Jamie\", \"Lannister\", \"Lannister\", \"Casterly Rock\", 29)\n",
    "        ]\n",
    "schema = StructType([\n",
    "    StructField(\"firstname\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True),\n",
    "    StructField(\"house\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "sample_dataframe = spark.createDataFrame(data=data, schema=schema)\n",
    "sample_dataframe.write.mode(saveMode=\"overwrite\").format(\"delta\").save(\"data/delta-table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading delta file ...!\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Casterly Rock| 29|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "|   Eddard|    Stark|    Stark|   Winterfell| 46|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "print(\"Reading delta file ...!\")\n",
    "\n",
    "df = spark.read.format(\"delta\").load(\"data/delta-table\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update a delta table\n",
    "\n",
    "If updating whole table then, simply overwrite the delta table with write.mode(saveMode=”overwrite”) command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update data...!\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Casterly Rock| 29|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "|   Eddard|    Stark|    Stark|   Winterfell| 46|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Kings Landing| 37|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "|   Eddard|    Stark|    Stark|   Winterfell| 46|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update data in Delta\n",
    "print(\"Update data...!\")\n",
    "\n",
    "# delta table path\n",
    "deltaTable = DeltaTable.forPath(spark, \"data/delta-table\")\n",
    "deltaTable.toDF().show()\n",
    "\n",
    "deltaTable.update(\n",
    "    condition=expr(\"firstname == 'Jamie'\"),\n",
    "    set={\"firstname\": lit(\"Jamie\"), \"lastname\": lit(\"Lannister\"), \"house\": lit(\"Lannister\"),\n",
    "         \"location\": lit(\"Kings Landing\"), \"age\": lit(37)})\n",
    "\n",
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Record from table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting data...!\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Kings Landing| 37|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "|   Eddard|    Stark|    Stark|   Winterfell| 46|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Kings Landing| 37|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete Data\n",
    "print(\"Deleting data...!\")\n",
    "\n",
    "# delta table path\n",
    "deltaTable = DeltaTable.forPath(spark, \"data/delta-table\")\n",
    "deltaTable.toDF().show()\n",
    "\n",
    "deltaTable.delete(condition=expr(\"firstname == 'Eddard'\"))\n",
    "\n",
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Historic data for Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read old data...!\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Casterly Rock| 29|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "|   Eddard|    Stark|    Stark|   Winterfell| 46|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n",
      "+---------+---------+---------+-------------+---+\n",
      "|firstname| lastname|    house|     location|age|\n",
      "+---------+---------+---------+-------------+---+\n",
      "|    Jamie|Lannister|Lannister|Kings Landing| 37|\n",
      "|   Robert|Baratheon|Baratheon|   Storms End| 48|\n",
      "|   Eddard|    Stark|    Stark|   Winterfell| 46|\n",
      "+---------+---------+---------+-------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading Older version of Data\n",
    "print(\"Read old data...!\")\n",
    "\n",
    "df_versionzero = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"data/delta-table\")\n",
    "df_versionzero.show()\n",
    "\n",
    "df_versionzone = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(\"data/delta-table\")\n",
    "df_versionzone.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
